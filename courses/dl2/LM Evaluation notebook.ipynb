{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LM Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "import html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH=Path('data/aclImdb/')\n",
    "CLAS_PATH=Path('data/imdb_clas/')\n",
    "LM_PATH=Path('data/imdb_lm/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_lm = np.load(LM_PATH/'tmp'/'trn_ids.npy')\n",
    "val_lm = np.load(LM_PATH/'tmp'/'val_ids.npy')\n",
    "itos = pickle.load(open(LM_PATH/'tmp'/'itos.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab = 60000\n",
    "min_freq = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60002"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi = collections.defaultdict(lambda:0, {v:k for k,v in enumerate(itos)})\n",
    "len(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60002, 90000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vs=len(itos)\n",
    "vs,len(trn_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_sz,nh,nl = 400,1150,3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load existing LM model and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_PATH = PATH/'models'/'wt103'\n",
    "PRE_LM_PATH = PRE_PATH/'fwd_wt103.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgts = torch.load(PRE_LM_PATH, map_location=lambda storage, loc: storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd=1e-7\n",
    "bptt=70\n",
    "bs=250\n",
    "opt_fn = partial(optim.Adam, betas=(0.8, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dl = LanguageModelLoader(np.concatenate(trn_lm), bs, bptt)\n",
    "val_dl = LanguageModelLoader(np.concatenate(val_lm), bs, bptt)\n",
    "md = LanguageModelData(PATH, 1, vs, trn_dl, val_dl, bs=bs, bptt=bptt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "drops = np.array([0.25, 0.1, 0.2, 0.02, 0.15])*0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner= md.get_model(opt_fn, em_sz, nh, nl, \n",
    "    dropouti=drops[0], dropout=drops[1], wdrop=drops[2], dropoute=drops[3], dropouth=drops[4])\n",
    "\n",
    "learner.metrics = [accuracy]\n",
    "learner.unfreeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace weights from classifier-encoder (not LM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.load('lm1')\n",
    "#learner.load_encoder('lm1_enc')\n",
    "learner.load_encoder('clas_2_enc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosine similarity - to check quality of our sentence encoder\n",
    "def cos_sim(v1,v2):\n",
    "    return F.cosine_similarity(T(v1).unsqueeze(0),T(v2).unsqueeze(0)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Round 1 - simple sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_inp = [\"i like apples\",\n",
    "         \"i want to buy some apples\",\n",
    "         \"where is your cell phone\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = Tokenizer().proc_all_mp(partition_by_cores(x_inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['i', 'like', 'apples'],\n",
       " ['i', 'want', 'to', 'buy', 'some', 'apples'],\n",
       " ['where', 'is', 'your', 'cell', 'phone']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[12, 52, 13154], [12, 203, 8, 808, 64, 13154], [134, 9, 146, 2739, 1668]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [[stoi[o1] for o1 in o] for o in tok]; X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([Variable containing:\n",
       "  ( 0  ,.,.) = \n",
       "    6.7115e-02 -1.3268e-03 -3.3807e-02  ...  -2.1760e-03 -1.7191e-03 -6.0852e-01\n",
       "   -4.6452e-04  1.6626e-03  8.8850e-02  ...  -1.8400e-04 -2.5501e-04 -4.1492e-04\n",
       "   -1.7479e-03  1.8946e-01  5.1639e-03  ...   1.3672e-01 -1.3180e-02  4.6813e-02\n",
       "    4.5800e-01  2.7667e-02 -7.9878e-02  ...   2.4866e-01 -1.9402e-01  4.1230e-01\n",
       "    5.2607e-01  1.8060e-02 -1.0414e-01  ...   1.4630e-01 -9.0713e-02  1.8234e-01\n",
       "  [torch.FloatTensor of size 1x5x1150], Variable containing:\n",
       "  ( 0  ,.,.) = \n",
       "   -2.6255e-02  1.1901e-02  2.0462e-03  ...  -3.1233e-02 -2.8014e-01  6.2324e-04\n",
       "   -3.3963e-02 -2.3060e-02  2.3785e-03  ...   5.5123e-03 -2.6828e-02  2.5454e-04\n",
       "   -1.8081e-03  7.7851e-03  1.5832e-02  ...  -1.0883e-02 -4.6499e-02 -1.2019e-04\n",
       "   -1.9474e-02 -1.4098e-02  8.2105e-03  ...  -5.3911e-02 -2.8161e-02  4.9225e-04\n",
       "   -2.3617e-02 -4.9448e-03  1.8774e-02  ...  -3.8561e-02  9.5322e-03 -1.4935e-03\n",
       "  [torch.FloatTensor of size 1x5x1150], Variable containing:\n",
       "  ( 0 ,.,.) = \n",
       "   -0.0975  0.0551 -0.0567  ...  -0.0782 -0.0829  0.0328\n",
       "   -0.0974  0.0417 -0.0540  ...   0.1154 -0.0000  0.0322\n",
       "    0.0480 -0.0012 -0.0817  ...   0.1875  0.0551  0.0146\n",
       "   -0.0712  0.0119 -0.0407  ...   0.1785 -0.0744 -0.0695\n",
       "    0.1248 -0.0271  0.0215  ...   0.4363 -0.0855  0.0340\n",
       "  [torch.FloatTensor of size 1x5x400]], [Variable containing:\n",
       "  ( 0  ,.,.) = \n",
       "    0.0750 -0.0015 -0.0378  ...  -0.0024 -0.0019 -0.6799\n",
       "   -0.0005  0.0019  0.0993  ...  -0.0002 -0.0003 -0.0005\n",
       "   -0.0020  0.2117  0.0058  ...   0.1528 -0.0147  0.0000\n",
       "    0.5117  0.0309 -0.0892  ...   0.2778 -0.2168  0.4607\n",
       "    0.5878  0.0202 -0.1164  ...   0.1635 -0.1014  0.2037\n",
       "  [torch.FloatTensor of size 1x5x1150], Variable containing:\n",
       "  ( 0  ,.,.) = \n",
       "   -0.0293  0.0133  0.0023  ...  -0.0349 -0.3130  0.0007\n",
       "   -0.0379 -0.0258  0.0027  ...   0.0062 -0.0300  0.0003\n",
       "   -0.0020  0.0087  0.0177  ...  -0.0122 -0.0520 -0.0001\n",
       "   -0.0218 -0.0158  0.0092  ...  -0.0602 -0.0315  0.0005\n",
       "   -0.0264 -0.0055  0.0210  ...  -0.0431  0.0107 -0.0000\n",
       "  [torch.FloatTensor of size 1x5x1150], Variable containing:\n",
       "  ( 0 ,.,.) = \n",
       "   -0.0975  0.0551 -0.0567  ...  -0.0782 -0.0829  0.0328\n",
       "   -0.0974  0.0417 -0.0540  ...   0.1154 -0.0000  0.0322\n",
       "    0.0480 -0.0012 -0.0817  ...   0.1875  0.0551  0.0146\n",
       "   -0.0712  0.0119 -0.0407  ...   0.1785 -0.0744 -0.0695\n",
       "    0.1248 -0.0271  0.0215  ...   0.4363 -0.0855  0.0340\n",
       "  [torch.FloatTensor of size 1x5x400]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = learner.model[0]\n",
    "kk=m(V(T([X[2]])));kk #last sentence in X - word level encoding....10 words 400 dim vecs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = learner.model\n",
    "\n",
    "# Set batch size to 1\n",
    "#m[0].bs=1\n",
    "# Turn off dropout\n",
    "#m.eval()\n",
    "# Reset hidden state\n",
    "#m.reset()\n",
    "\n",
    "kk0=m[0](V(T([X[0]]))) #first sentence in X - word level encoding....10 words 400 dim vecs\n",
    "kk1=m[0](V(T([X[1]]))) #second sentence in X - word level encoding....10 words 400 dim vecs\n",
    "kk2=m[0](V(T([X[2]]))) #third sentence in X - word level encoding....10 words 400 dim vecs\n",
    "\n",
    "\n",
    "kk0=to_np(kk0)\n",
    "kk1=to_np(kk1)\n",
    "kk2=to_np(kk2)\n",
    "\n",
    "\n",
    "kk0 = (kk0[0][2][0][-1]) # 1st sentence encoding 400 dims. -1 is the last element that's supposed to have the final encoded state\n",
    "kk1 = (kk1[0][2][0][-1]) # 2nd sentence encoding 400 dims\n",
    "kk2 = (kk2[0][2][0][-1]) # 3rd sentence encoding 400 dims\n",
    "\n",
    "\n",
    "kk1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i like apples', 'i want to buy some apples', 'where is your cell phone']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8836122751235962, 0.17896205186843872, 0.23436345160007477)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(kk0,kk1), cos_sim(kk1,kk2), cos_sim(kk0,kk2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.230761"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.inner(kk0,kk1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83972144"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.inner(kk1,kk2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0898541"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.inner(kk0,kk2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Round 2 - increase sentence complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_inp = [\"i like apples and oranges\",\n",
    "         \"i hate all fruits especially apples and oranges\",\n",
    "         \"i am going to buy some apples and oranges\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = Tokenizer().proc_all_mp(partition_by_cores(x_inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['i', 'like', 'apples', 'and', 'oranges'],\n",
       " ['i', 'hate', 'all', 'fruits', 'especially', 'apples', 'and', 'oranges'],\n",
       " ['i', 'am', 'going', 'to', 'buy', 'some', 'apples', 'and', 'oranges']]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[12, 52, 13154, 5, 20864],\n",
       " [12, 738, 43, 22144, 280, 13154, 5, 20864],\n",
       " [12, 261, 182, 8, 808, 64, 13154, 5, 20864]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [[stoi[o1] for o1 in o] for o in tok]; X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = learner.model\n",
    "\n",
    "# Set batch size to 1\n",
    "#m[0].bs=1\n",
    "# Turn off dropout\n",
    "#m.eval()\n",
    "# Reset hidden state\n",
    "#m.reset()\n",
    "\n",
    "kk0=m[0](V(T([X[0]]))) #first sentence in X - word level encoding....10 words 400 dim vecs\n",
    "kk1=m[0](V(T([X[1]]))) #second sentence in X - word level encoding....10 words 400 dim vecs\n",
    "kk2=m[0](V(T([X[2]]))) #third sentence in X - word level encoding....10 words 400 dim vecs\n",
    "\n",
    "\n",
    "kk0=to_np(kk0)\n",
    "kk1=to_np(kk1)\n",
    "kk2=to_np(kk2)\n",
    "\n",
    "\n",
    "kk0 = (kk0[0][2][0][-1]) # 1st sentence encoding 400 dims. -1 is the last element that's supposed to have the final encoded state\n",
    "kk1 = (kk1[0][2][0][-1]) # 2nd sentence encoding 400 dims\n",
    "kk2 = (kk2[0][2][0][-1]) # 3rd sentence encoding 400 dims\n",
    "\n",
    "\n",
    "kk1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i like apples and oranges',\n",
       " 'i hate all fruits especially apples and oranges',\n",
       " 'i am going to buy some apples and oranges']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.503886342048645, 0.8975854516029358, 0.46116968989372253)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(kk0,kk1), cos_sim(kk1,kk2), cos_sim(kk0,kk2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89525676"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.inner(kk0,kk1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8896785"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.inner(kk1,kk2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98151237"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.inner(kk0,kk2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Round 3 - more complex!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_inp = [\"let's talk about fruits for a second. Apples are nice. Oranges too. I kinda like them.\",\n",
    "         \"i compared the prices of apples and oranges at walmart and kroger stores\",\n",
    "         \"oh you wanna talk about apples. sure. i am not sure if i have said this before but i do like them and oranges.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = Tokenizer().proc_all_mp(partition_by_cores(x_inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['let',\n",
       "  \"'s\",\n",
       "  'talk',\n",
       "  'about',\n",
       "  'fruits',\n",
       "  'for',\n",
       "  'a',\n",
       "  'second',\n",
       "  '.',\n",
       "  'apples',\n",
       "  'are',\n",
       "  'nice',\n",
       "  '.',\n",
       "  'oranges',\n",
       "  'too',\n",
       "  '.',\n",
       "  'i',\n",
       "  'kinda',\n",
       "  'like',\n",
       "  'them',\n",
       "  '.'],\n",
       " ['i',\n",
       "  'compared',\n",
       "  'the',\n",
       "  'prices',\n",
       "  'of',\n",
       "  'apples',\n",
       "  'and',\n",
       "  'oranges',\n",
       "  'at',\n",
       "  'walmart',\n",
       "  'and',\n",
       "  'kroger',\n",
       "  'stores'],\n",
       " ['oh',\n",
       "  'you',\n",
       "  'wanna',\n",
       "  'talk',\n",
       "  'about',\n",
       "  'apples',\n",
       "  '.',\n",
       "  'sure',\n",
       "  '.',\n",
       "  'i',\n",
       "  'am',\n",
       "  'not',\n",
       "  'sure',\n",
       "  'if',\n",
       "  'i',\n",
       "  'have',\n",
       "  'said',\n",
       "  'this',\n",
       "  'before',\n",
       "  'but',\n",
       "  'i',\n",
       "  'do',\n",
       "  'like',\n",
       "  'them',\n",
       "  'and',\n",
       "  'oranges',\n",
       "  '.']]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[302,\n",
       "  16,\n",
       "  713,\n",
       "  58,\n",
       "  22144,\n",
       "  22,\n",
       "  6,\n",
       "  349,\n",
       "  3,\n",
       "  13154,\n",
       "  33,\n",
       "  358,\n",
       "  3,\n",
       "  20864,\n",
       "  116,\n",
       "  3,\n",
       "  12,\n",
       "  2040,\n",
       "  52,\n",
       "  110,\n",
       "  3],\n",
       " [12, 1128, 2, 12023, 7, 13154, 5, 20864, 44, 17680, 5, 0, 5400],\n",
       " [452,\n",
       "  26,\n",
       "  2890,\n",
       "  713,\n",
       "  58,\n",
       "  13154,\n",
       "  3,\n",
       "  273,\n",
       "  3,\n",
       "  12,\n",
       "  261,\n",
       "  32,\n",
       "  273,\n",
       "  62,\n",
       "  12,\n",
       "  36,\n",
       "  326,\n",
       "  13,\n",
       "  176,\n",
       "  24,\n",
       "  12,\n",
       "  57,\n",
       "  52,\n",
       "  110,\n",
       "  5,\n",
       "  20864,\n",
       "  3]]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [[stoi[o1] for o1 in o] for o in tok]; X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400,)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = learner.model\n",
    "\n",
    "# Set batch size to 1\n",
    "#m[0].bs=1\n",
    "# Turn off dropout\n",
    "#m.eval()\n",
    "# Reset hidden state\n",
    "#m.reset()\n",
    "\n",
    "kk0=m[0](V(T([X[0]]))) #first sentence in X - word level encoding....10 words 400 dim vecs\n",
    "kk1=m[0](V(T([X[1]]))) #second sentence in X - word level encoding....10 words 400 dim vecs\n",
    "kk2=m[0](V(T([X[2]]))) #third sentence in X - word level encoding....10 words 400 dim vecs\n",
    "\n",
    "\n",
    "kk0=to_np(kk0)\n",
    "kk1=to_np(kk1)\n",
    "kk2=to_np(kk2)\n",
    "\n",
    "\n",
    "kk0 = (kk0[0][2][0][-1]) # 1st sentence encoding 400 dims. -1 is the last element that's supposed to have the final encoded state\n",
    "kk1 = (kk1[0][2][0][-1]) # 2nd sentence encoding 400 dims\n",
    "kk2 = (kk2[0][2][0][-1]) # 3rd sentence encoding 400 dims\n",
    "\n",
    "\n",
    "kk1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"let's talk about fruits for a second. Apples are nice. Oranges too. I kinda like them.\",\n",
       " 'i compared the prices of apples and oranges at walmart and kroger stores',\n",
       " 'oh you wanna talk about apples. sure. i am not sure if i have said this before but i do like them and oranges.']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2883625328540802, 0.2486269772052765, 0.9720225930213928)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(kk0,kk1), cos_sim(kk1,kk2), cos_sim(kk0,kk2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5486556"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.inner(kk0,kk1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49776977"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.inner(kk1,kk2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5571241"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.inner(kk0,kk2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Round 4 - really complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_inp = [\"there is no comparison here. you are comparing apples to oranges\",\n",
    "         \"i compared the prices of apples and oranges at walmart and kroger stores\",\n",
    "         \"i don't see anything common between these two categories.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = Tokenizer().proc_all_mp(partition_by_cores(x_inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['there',\n",
       "  'is',\n",
       "  'no',\n",
       "  'comparison',\n",
       "  'here',\n",
       "  '.',\n",
       "  'you',\n",
       "  'are',\n",
       "  'comparing',\n",
       "  'apples',\n",
       "  'to',\n",
       "  'oranges'],\n",
       " ['i',\n",
       "  'compared',\n",
       "  'the',\n",
       "  'prices',\n",
       "  'of',\n",
       "  'apples',\n",
       "  'and',\n",
       "  'oranges',\n",
       "  'at',\n",
       "  'walmart',\n",
       "  'and',\n",
       "  'kroger',\n",
       "  'stores'],\n",
       " ['i',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  'see',\n",
       "  'anything',\n",
       "  'common',\n",
       "  'between',\n",
       "  'these',\n",
       "  'two',\n",
       "  'categories',\n",
       "  '.']]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[53, 9, 73, 1884, 148, 3, 26, 33, 4324, 13154, 8, 20864],\n",
       " [12, 1128, 2, 12023, 7, 13154, 5, 20864, 44, 17680, 5, 0, 5400],\n",
       " [12, 57, 29, 83, 255, 1116, 222, 150, 126, 9281, 3]]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [[stoi[o1] for o1 in o] for o in tok]; X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400,)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = learner.model\n",
    "\n",
    "# Set batch size to 1\n",
    "#m[0].bs=1\n",
    "# Turn off dropout\n",
    "#m.eval()\n",
    "# Reset hidden state\n",
    "#m.reset()\n",
    "\n",
    "kk0=m[0](V(T([X[0]]))) #first sentence in X - word level encoding....10 words 400 dim vecs\n",
    "kk1=m[0](V(T([X[1]]))) #second sentence in X - word level encoding....10 words 400 dim vecs\n",
    "kk2=m[0](V(T([X[2]]))) #third sentence in X - word level encoding....10 words 400 dim vecs\n",
    "\n",
    "\n",
    "kk0=to_np(kk0)\n",
    "kk1=to_np(kk1)\n",
    "kk2=to_np(kk2)\n",
    "\n",
    "\n",
    "kk0 = (kk0[0][2][0][-1]) # 1st sentence encoding 400 dims. -1 is the last element that's supposed to have the final encoded state\n",
    "kk1 = (kk1[0][2][0][-1]) # 2nd sentence encoding 400 dims\n",
    "kk2 = (kk2[0][2][0][-1]) # 3rd sentence encoding 400 dims\n",
    "\n",
    "\n",
    "kk1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['there is no comparison here. you are comparing apples to oranges',\n",
       " 'i compared the prices of apples and oranges at walmart and kroger stores',\n",
       " \"i don't see anything common between these two categories.\"]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.57721346616745, 0.2024388462305069, 0.22252123057842255)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(kk0,kk1), cos_sim(kk1,kk2), cos_sim(kk0,kk2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97971964"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.inner(kk0,kk1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37234193"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.inner(kk1,kk2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34369394"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.inner(kk0,kk2)"
   ]
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/0dd0df21cf404cf2bb51d0148c8b7d8b"
  },
  "gist": {
   "data": {
    "description": "fastai.text imdb example",
    "public": true
   },
   "id": "0dd0df21cf404cf2bb51d0148c8b7d8b"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "86px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
