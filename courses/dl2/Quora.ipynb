{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Similarity Evaluation - using pre-trained weights from the LM/Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "import html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH=Path('data/aclImdb/')\n",
    "CLAS_PATH=Path('data/imdb_clas/')\n",
    "LM_PATH=Path('data/imdb_lm/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_lm = np.load(LM_PATH/'tmp'/'trn_ids.npy')[:10]\n",
    "val_lm = np.load(LM_PATH/'tmp'/'val_ids.npy')[:10]\n",
    "itos = pickle.load(open(LM_PATH/'tmp'/'itos.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60002"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi = collections.defaultdict(lambda:0, {v:k for k,v in enumerate(itos)})\n",
    "len(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab = 60000\n",
    "min_freq = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60002, 10)"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vs=len(itos)\n",
    "vs,len(trn_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_sz,nh,nl = 400,1150,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(itos, open('itos_41k.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60002"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(itos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load existing LM model and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_PATH = PATH/'models'/'wt103'\n",
    "PRE_LM_PATH = PRE_PATH/'fwd_wt103.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgts = torch.load(PRE_LM_PATH, map_location=lambda storage, loc: storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd=1e-7\n",
    "bptt=70\n",
    "bs=250\n",
    "opt_fn = partial(optim.Adam, betas=(0.8, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dl = LanguageModelLoader(np.concatenate(trn_lm), bs, bptt)\n",
    "val_dl = LanguageModelLoader(np.concatenate(val_lm), bs, bptt)\n",
    "md = LanguageModelData(PATH, 1, vs, trn_dl, val_dl, bs=bs, bptt=bptt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "drops = np.array([0.25, 0.1, 0.2, 0.02, 0.15])*0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner= md.get_model(opt_fn, em_sz, nh, nl, \n",
    "    dropouti=drops[0], dropout=drops[1], wdrop=drops[2], dropoute=drops[3], dropouth=drops[4])\n",
    "\n",
    "learner.metrics = [accuracy]\n",
    "learner.unfreeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace weights from classifier-encoder (not LM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.load('lm1')\n",
    "#learner.load_encoder('lm1_enc')\n",
    "learner.load_encoder('clas_2_enc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal: Encode 3 sentences using a pre-trained encoder and check the similarity scores between each pair of sentences. We use 2 methods to calculate semantic similarity: cosine similarity and inner product of encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosine similarity - to check quality of our sentence encoder\n",
    "def cos_sim(v1,v2):\n",
    "    return F.cosine_similarity(T(v1).unsqueeze(0),T(v2).unsqueeze(0)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "itos = pickle.load(open('itos_41k.pkl', 'rb'))\n",
    "stoi = collections.defaultdict(lambda:0, {v:k for k,v in enumerate(itos)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create data for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_inp = [\"i like apples\",\n",
    "         \"i want to buy some apples\",\n",
    "         \"where is your cell phone\"]\n",
    "\n",
    "x2_inp = [\"i like apples and oranges\",\n",
    "         \"i love all fruits especially apples and oranges\",\n",
    "         \"where is the new movie showing?\"]\n",
    "\n",
    "x3_inp = [\"let's talk about fruits for a second. Apples are nice. Oranges too. I kinda like them.\",\n",
    "         \"i compared the prices of apples and oranges at walmart and kroger stores\",\n",
    "         \"oh you wanna talk about apples. sure. i am not sure if i have said this before but i do like them and oranges.\"]\n",
    "\n",
    "x4_inp = [\"there is no comparison here. you are comparing apples to oranges\",\n",
    "         \"i compared the prices of apples and oranges at walmart and kroger stores\",\n",
    "         \"i don't see anything common between these two categories.\"]\n",
    "\n",
    "x5_inp = [\"i would love to own a nice boat and go sailing in the pacific ocean\",\n",
    "         \"i'm thinking of getting a fancy boat and set sail into the south pacific\",\n",
    "         \"i wish to own a small house and live there without any worries\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok1 = Tokenizer().proc_all(x1_inp,'en')\n",
    "tok2 = Tokenizer().proc_all(x2_inp,'en')\n",
    "tok3 = Tokenizer().proc_all(x3_inp,'en')\n",
    "tok4 = Tokenizer().proc_all(x4_inp,'en')\n",
    "tok5 = Tokenizer().proc_all(x5_inp,'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = [[stoi[o1] for o1 in o] for o in tok1]\n",
    "X2 = [[stoi[o1] for o1 in o] for o in tok2]\n",
    "X3 = [[stoi[o1] for o1 in o] for o in tok3]\n",
    "X4 = [[stoi[o1] for o1 in o] for o in tok4]\n",
    "X5 = [[stoi[o1] for o1 in o] for o in tok5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialRNN(\n",
       "  (0): RNN_Encoder(\n",
       "    (encoder): Embedding(60002, 400, padding_idx=1)\n",
       "    (encoder_with_dropout): EmbeddingDropout(\n",
       "      (embed): Embedding(60002, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDrop(\n",
       "        (module): LSTM(400, 1150, dropout=0.105)\n",
       "      )\n",
       "      (1): WeightDrop(\n",
       "        (module): LSTM(1150, 1150, dropout=0.105)\n",
       "      )\n",
       "      (2): WeightDrop(\n",
       "        (module): LSTM(1150, 400, dropout=0.105)\n",
       "      )\n",
       "    )\n",
       "    (dropouti): LockedDropout(\n",
       "    )\n",
       "    (dropouths): ModuleList(\n",
       "      (0): LockedDropout(\n",
       "      )\n",
       "      (1): LockedDropout(\n",
       "      )\n",
       "      (2): LockedDropout(\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=60002, bias=False)\n",
       "    (dropout): LockedDropout(\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 590,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = learner.model\n",
    "# Turn off dropout\n",
    "m.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create reusable func for inference\n",
    "#Laid out for readability - will refactor later\n",
    "def run_model(X):\n",
    "    kk0=m[0](V(T([X[0]]))) #first sentence in X - sentence level encoding....10 words 400 dim vecs\n",
    "    kk1=m[0](V(T([X[1]]))) #second sentence in X - sentence level encoding....10 words 400 dim vecs\n",
    "    kk2=m[0](V(T([X[2]]))) #third sentence in X - sentence level encoding....10 words 400 dim vecs\n",
    "\n",
    "    kk0=to_np(kk0)\n",
    "    kk1=to_np(kk1)\n",
    "    kk2=to_np(kk2)\n",
    "\n",
    "    kk0 = (kk0[0][2][0][-1]) # 1st sentence encoding 400 dims. -1 is the last element that's supposed to have the final encoded state\n",
    "    kk1 = (kk1[0][2][0][-1]) # 2nd sentence encoding 400 dims\n",
    "    kk2 = (kk2[0][2][0][-1]) # 3rd sentence encoding 400 dims\n",
    "    \n",
    "    return kk0,kk1,kk2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Round 1 - simple sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400,)"
      ]
     },
     "execution_count": 592,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kk0,kk1,kk2 = run_model(X1)\n",
    "kk1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i like apples', 'i want to buy some apples', 'where is your cell phone']"
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1_inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9999998807907104, 0.06893263012170792, 0.06893263757228851)"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(kk0,kk1), cos_sim(kk1,kk2), cos_sim(kk0,kk2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.2282677, 0.16939801, 0.169398)"
      ]
     },
     "execution_count": 595,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.inner(kk0,kk1),np.inner(kk1,kk2),np.inner(kk0,kk2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Round 2 - increase sentence complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400,)"
      ]
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kk0,kk1,kk2 = run_model(X2)\n",
    "kk1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i like apples and oranges',\n",
       " 'i love all fruits especially apples and oranges',\n",
       " 'where is the new movie showing?']"
      ]
     },
     "execution_count": 597,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2_inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8213068842887878, 0.22487039864063263, 0.2921583652496338)"
      ]
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(kk0,kk1), cos_sim(kk1,kk2), cos_sim(kk0,kk2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.1879294, 0.73501706, 0.5341433)"
      ]
     },
     "execution_count": 599,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.inner(kk0,kk1),np.inner(kk1,kk2),np.inner(kk0,kk2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Round 3 - more complex!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400,)"
      ]
     },
     "execution_count": 600,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kk0,kk1,kk2 = run_model(X3)\n",
    "kk1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"let's talk about fruits for a second. Apples are nice. Oranges too. I kinda like them.\",\n",
       " 'i compared the prices of apples and oranges at walmart and kroger stores',\n",
       " 'oh you wanna talk about apples. sure. i am not sure if i have said this before but i do like them and oranges.']"
      ]
     },
     "execution_count": 601,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3_inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.043320432305336, 0.043320432305336, 1.0000001192092896)"
      ]
     },
     "execution_count": 602,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(kk0,kk1), cos_sim(kk1,kk2), cos_sim(kk0,kk2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.14767489, 0.14767489, 1.7979703)"
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.inner(kk0,kk1),np.inner(kk1,kk2),np.inner(kk0,kk2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Round 4 - really complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400,)"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kk0,kk1,kk2 = run_model(X4)\n",
    "kk1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['there is no comparison here. you are comparing apples to oranges',\n",
       " 'i compared the prices of apples and oranges at walmart and kroger stores',\n",
       " \"i don't see anything common between these two categories.\"]"
      ]
     },
     "execution_count": 605,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x4_inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0017274579731747508, 0.043320432305336, 0.02612287364900112)"
      ]
     },
     "execution_count": 606,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(kk0,kk1), cos_sim(kk1,kk2), cos_sim(kk0,kk2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0115689635, 0.14767492, 0.09227343)"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.inner(kk0,kk1),np.inner(kk1,kk2),np.inner(kk0,kk2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As you can see, the model is not able to get the nuance in Round 4.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Round 5 - nuance check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400,)"
      ]
     },
     "execution_count": 608,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kk0,kk1,kk2 = run_model(X5)\n",
    "kk1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i would love to own a nice boat and go sailing in the pacific ocean',\n",
       " \"i'm thinking of getting a fancy boat and set sail into the south pacific\",\n",
       " 'i wish to own a small house and live there without any worries']"
      ]
     },
     "execution_count": 611,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x5_inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5177718997001648, 0.14863775670528412, 0.046706970781087875)"
      ]
     },
     "execution_count": 612,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(kk0,kk1), cos_sim(kk1,kk2), cos_sim(kk0,kk2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7448063, 0.67609465, 0.48657796)"
      ]
     },
     "execution_count": 613,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.inner(kk0,kk1),np.inner(kk1,kk2),np.inner(kk0,kk2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As you can see, the model did ok-ish but is not able to get the nuance. 0 and 2 should have scored higher**\n",
    "\n",
    "We have been using the encoder from the IMDB classifier for comparing semantic similarity. Let's see if we can do better by creating a new model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quora dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a standard dataset specifically meant for the semantic similarity task.\n",
    "Let's use the quora kaggle dataset that contains pairs of english sentences and the goal is to predict if a given pair of sentences are semantically similar(meaning).\n",
    "\n",
    "y=1 indicates they have the same meaning  \n",
    "y=0 means the pair differ in meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question pairs: 404290\n"
     ]
    }
   ],
   "source": [
    "#QUESTION_PAIRS_FILE = '/datasets/quora_duplicate_questions.tsv'\n",
    "#print(\"Processing\", QUESTION_PAIRS_FILE)\n",
    "\n",
    "question1 = []\n",
    "question2 = []\n",
    "is_duplicate = []\n",
    "with open(QUESTION_PAIRS_FILE, encoding='utf-8') as csvfile:\n",
    "    reader = csv.DictReader(csvfile, delimiter='\\t')\n",
    "    for row in reader:\n",
    "        question1.append(row['question1'])\n",
    "        question2.append(row['question2'])\n",
    "        is_duplicate.append(int(row['is_duplicate']))\n",
    "\n",
    "print('Question pairs: %d' % len(question1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What is the step by step guide to invest in share market in india?',\n",
       " 'What is the story of Kohinoor (Koh-i-Noor) Diamond?',\n",
       " 'How can I increase the speed of my internet connection while using a VPN?',\n",
       " 'Why am I mentally very lonely? How can I solve it?',\n",
       " 'Which one dissolve in water quikly sugar, salt, methane and carbon di oxide?',\n",
       " 'Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me?',\n",
       " 'Should I buy tiago?',\n",
       " 'How can I be a good geologist?',\n",
       " 'When do you use シ instead of し?',\n",
       " 'Motorola (company): Can I hack my Charter Motorolla DCX3400?']"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What is the step by step guide to invest in share market?',\n",
       " 'What would happen if the Indian government stole the Kohinoor (Koh-i-Noor) diamond back?',\n",
       " 'How can Internet speed be increased by hacking through DNS?',\n",
       " 'Find the remainder when [math]23^{24}[/math] is divided by 24,23?',\n",
       " 'Which fish would survive in salt water?',\n",
       " \"I'm a triple Capricorn (Sun, Moon and ascendant in Capricorn) What does this say about me?\",\n",
       " 'What keeps childern active and far from phone and video games?',\n",
       " 'What should I do to be a great geologist?',\n",
       " 'When do you use \"&\" instead of \"and\"?',\n",
       " 'How do I hack Motorola DCX3400 for free internet?']"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404290, 404290, 404290)"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(question1),len(question2),len(is_duplicate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 1, 0, 1, 0, 0]"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_duplicate[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksize=64000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_q1 = Tokenizer.proc_all_mp(partition_by_cores(question1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_q2 = Tokenizer.proc_all_mp(partition_by_cores(question2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['what',\n",
       "  'is',\n",
       "  'the',\n",
       "  'step',\n",
       "  'by',\n",
       "  'step',\n",
       "  'guide',\n",
       "  'to',\n",
       "  'invest',\n",
       "  'in',\n",
       "  'share',\n",
       "  'market',\n",
       "  '?'],\n",
       " ['what',\n",
       "  'would',\n",
       "  'happen',\n",
       "  'if',\n",
       "  'the',\n",
       "  'indian',\n",
       "  'government',\n",
       "  'stole',\n",
       "  'the',\n",
       "  'kohinoor',\n",
       "  '(',\n",
       "  'koh',\n",
       "  '-',\n",
       "  'i',\n",
       "  '-',\n",
       "  'noor',\n",
       "  ')',\n",
       "  'diamond',\n",
       "  'back',\n",
       "  '?'],\n",
       " ['how',\n",
       "  'can',\n",
       "  'internet',\n",
       "  'speed',\n",
       "  'be',\n",
       "  'increased',\n",
       "  'by',\n",
       "  'hacking',\n",
       "  'through',\n",
       "  't_up',\n",
       "  'dns',\n",
       "  '?'],\n",
       " ['find',\n",
       "  'the',\n",
       "  'remainder',\n",
       "  'when',\n",
       "  '[',\n",
       "  'math]23^{24',\n",
       "  '}',\n",
       "  '[',\n",
       "  '/',\n",
       "  'math',\n",
       "  ']',\n",
       "  'is',\n",
       "  'divided',\n",
       "  'by',\n",
       "  '24,23',\n",
       "  '?'],\n",
       " ['which', 'fish', 'would', 'survive', 'in', 'salt', 'water', '?'],\n",
       " ['i',\n",
       "  \"'m\",\n",
       "  'a',\n",
       "  'triple',\n",
       "  'capricorn',\n",
       "  '(',\n",
       "  'sun',\n",
       "  ',',\n",
       "  'moon',\n",
       "  'and',\n",
       "  'ascendant',\n",
       "  'in',\n",
       "  'capricorn',\n",
       "  ')',\n",
       "  'what',\n",
       "  'does',\n",
       "  'this',\n",
       "  'say',\n",
       "  'about',\n",
       "  'me',\n",
       "  '?'],\n",
       " ['what',\n",
       "  'keeps',\n",
       "  'childern',\n",
       "  'active',\n",
       "  'and',\n",
       "  'far',\n",
       "  'from',\n",
       "  'phone',\n",
       "  'and',\n",
       "  'video',\n",
       "  'games',\n",
       "  '?'],\n",
       " ['what', 'should', 'i', 'do', 'to', 'be', 'a', 'great', 'geologist', '?'],\n",
       " ['when',\n",
       "  'do',\n",
       "  'you',\n",
       "  'use',\n",
       "  '\"',\n",
       "  '&',\n",
       "  '\"',\n",
       "  'instead',\n",
       "  'of',\n",
       "  '\"',\n",
       "  'and',\n",
       "  '\"',\n",
       "  '?'],\n",
       " ['how',\n",
       "  'do',\n",
       "  'i',\n",
       "  'hack',\n",
       "  'motorola',\n",
       "  't_up',\n",
       "  'dcx3400',\n",
       "  'for',\n",
       "  'free',\n",
       "  'internet',\n",
       "  '?']]"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_q2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "ques = tok_q1 + tok_q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = Counter(p for o in ques for p in o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('?', 852054),\n",
       " ('the', 377634),\n",
       " ('what', 324433),\n",
       " ('is', 271122),\n",
       " ('i', 223363),\n",
       " ('how', 220656),\n",
       " ('a', 211277),\n",
       " ('to', 205717),\n",
       " ('in', 196940),\n",
       " ('do', 169773),\n",
       " ('of', 159862),\n",
       " ('are', 146580),\n",
       " ('and', 133925),\n",
       " ('can', 114550),\n",
       " ('for', 104498),\n",
       " (',', 98321),\n",
       " ('t_up', 97217),\n",
       " ('you', 93102),\n",
       " ('why', 84030),\n",
       " ('it', 71057),\n",
       " ('my', 70930),\n",
       " ('best', 70596),\n",
       " ('on', 60715),\n",
       " ('does', 59502),\n",
       " ('.', 49499)]"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq.most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab = 60000\n",
    "min_freq = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "itos = [o for o,c in freq.most_common(max_vocab) if c>min_freq]\n",
    "itos.insert(0, '_pad_')\n",
    "itos.insert(0, '_unk_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_unk_', '_pad_', '?', 'the', 'what', 'is', 'i', 'how', 'a', 'to']"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41665"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_unk_', '_pad_', '?', 'the', 'what', 'is', 'i', 'how', 'a', 'to']"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi = collections.defaultdict(lambda:0, {v:k for k,v in enumerate(itos)})\n",
    "list(stoi)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = np.array([[stoi[o] for o in p] for p in tok_q1])\n",
    "q2 = np.array([[stoi[o] for o in p] for p in tok_q2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((404290,), (404290,))"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1.shape,q2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[4, 5, 3, 1254, 69, 1254, 2576, 9, 589, 10, 773, 390, 10, 43, 2]'"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(q1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['what', 'is', 'the', 'step', 'by', 'step', 'guide', 'to', 'invest', 'in', 'share', 'market', 'in',\n",
       "       'india', '?'], dtype='<U65')"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos_arr = np.array(itos)\n",
    "itos_arr[q1[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('q1.npy', q1)\n",
    "# np.save('q2.npy', q2)\n",
    "# pickle.dump(itos, open('itos.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = np.load('q1.npy')\n",
    "q2 = np.load('q2.npy')\n",
    "itos = pickle.load(open('itos_41k.pkl', 'rb'))\n",
    "stoi = collections.defaultdict(lambda:0, {v:k for k,v in enumerate(itos)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41665, 404290)"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vs=len(itos) #vocab size\n",
    "vs,len(q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "itos2 = pickle.load((PRE_PATH/'itos_wt103.pkl').open('rb'))\n",
    "stoi2 = collections.defaultdict(lambda:-1, {v:k for k,v in enumerate(itos2)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgts = torch.load(PRE_LM_PATH, map_location=lambda storage, loc: storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['0.encoder.weight', '0.encoder_with_dropout.embed.weight', '0.rnns.0.module.weight_ih_l0', '0.rnns.0.module.bias_ih_l0', '0.rnns.0.module.bias_hh_l0', '0.rnns.0.module.weight_hh_l0_raw', '0.rnns.1.module.weight_ih_l0', '0.rnns.1.module.bias_ih_l0', '0.rnns.1.module.bias_hh_l0', '0.rnns.1.module.weight_hh_l0_raw', '0.rnns.2.module.weight_ih_l0', '0.rnns.2.module.bias_ih_l0', '0.rnns.2.module.bias_hh_l0', '0.rnns.2.module.weight_hh_l0_raw', '1.decoder.weight'])"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wgts.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((400,),\n",
       " array([-0.0183 , -0.13826,  0.01438, -0.01285,  0.00407,  0.01944,  0.01149, -0.13282, -0.02295, -0.01722],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_wgts = to_np(wgts['0.encoder.weight'])\n",
    "row_m = enc_wgts.mean(0) \n",
    "row_m.shape, row_m[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embedding matrix and take token weights from wikitext103 if available\n",
    "# Use 60002 instead of 41665 for future embedding matrix where backbone encoder needs to be loaded.\n",
    "# not needed for simple model\n",
    "new_w = np.zeros((len(itos), em_sz), dtype=np.float32)\n",
    "for i,w in enumerate(itos):\n",
    "    r = stoi2[w]\n",
    "    new_w[i] = enc_wgts[r] if r>=0 else row_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41665, 400)"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgts['0.encoder.weight'] = T(new_w)\n",
    "wgts['0.encoder_with_dropout.embed.weight'] = T(np.copy(new_w))\n",
    "wgts['1.decoder.weight'] = T(np.copy(new_w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([41665, 400])"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wgts['1.decoder.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_keep = np.random.rand(len(q1))>0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_trn = q1[trn_keep]\n",
    "q2_trn = q2[trn_keep]\n",
    "lbl_trn = np.asarray(is_duplicate)[trn_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray([lbl_trn]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(T(np.array([lbl_trn[101]]).T)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(363796,)"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_trn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_val = q1[~trn_keep]\n",
    "q2_val = q2[~trn_keep]\n",
    "lbl_val = np.asarray(is_duplicate)[~trn_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40494, 1)"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbl_val = np.asarray([lbl_val]).T\n",
    "lbl_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(363796, 1)"
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbl_trn = np.asarray([lbl_trn]).T\n",
    "lbl_trn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 40494)"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbl_val = lbl_val.T\n",
    "lbl_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 363796)"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbl_trn = lbl_trn.T\n",
    "lbl_trn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41665, 400)"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vs,em_sz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairDataset(Dataset):\n",
    "    def __init__(self, X, y): self.x1,self.x2,self.y = X[0],X[1],y\n",
    "    def __getitem__(self, idx): return A(self.x1[idx], self.x2[idx], (T(self.y[idx]).float()))\n",
    "    def __len__(self): return len(self.x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ds = PairDataset(X=[q1_trn[:1000],q2_trn[:1000]],y=(lbl_trn[:1000]).T)\n",
    "val_ds = PairDataset(X=[q1_val[:100],q2_val[:100]],y=(lbl_val[:100]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ds = PairDataset(X=[q1_trn,q2_trn],y=(lbl_trn).T)\n",
    "val_ds = PairDataset(X=[q1_val,q2_val],y=(lbl_val).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([    4,    25, 11486,   113,     2]),\n",
       " array([    4,    25, 11486,  1370,     2]),\n",
       " array([1.], dtype=float32)]"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_ds.__getitem__(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unable to run with larger bs because of DataLoader transpose issue\n",
    "bs=48\n",
    "#bs=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "#??DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dl = DataLoader(trn_ds, bs, transpose=True, transpose_y=True, num_workers=1, \n",
    "                    pad_idx=1, pre_pad=False) #, sampler=trn_samp)\n",
    "val_dl = DataLoader(val_ds, bs, transpose=True, transpose_y=True, num_workers=1, \n",
    "                    pad_idx=1, pre_pad=False) #, sampler=val_samp)\n",
    "md = ModelData(PATH, trn_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(31, 40, 1), (33, 34, 1), (24, 36, 1), (32, 43, 1), (44, 37, 1)]"
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it = iter(trn_dl)\n",
    "its = [next(it) for i in range(5)]\n",
    "[(len(x1),len(x2),len(y)) for x1,x2,y in its]\n",
    "#[((y)) for x1,x2,y in its]\n",
    "#next(it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model - simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emb(vecs, itos, em_sz):\n",
    "    emb = nn.Embedding(len(itos), em_sz, padding_idx=1)\n",
    "    wgts = emb.weight.data\n",
    "    miss = []\n",
    "    for i,w in enumerate(itos):\n",
    "        try: wgts[i] = torch.from_numpy(vecs[i])\n",
    "        except: miss.append(w)\n",
    "    print(len(miss),miss[5:10])\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "nh,nl = 256,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairRNN(nn.Module):\n",
    "    #def __init__(self, vecs_enc, itos_enc, em_sz_enc, vecs_dec, itos_dec, em_sz_dec, nh, out_sl, nl=2):\n",
    "    def __init__(self, vecs, itos, em_sz, nh, out_sl=75, nl=2, bs=100):\n",
    "        super().__init__()\n",
    "        self.nl,self.nh,self.out_sl,self.bs = nl,nh,out_sl,bs\n",
    "        self.emb = create_emb(vecs, itos, em_sz)\n",
    "        self.emb_drop = nn.Dropout(0.15)\n",
    "        self.gru = nn.GRU(em_sz, nh, num_layers=nl, dropout=0.25)\n",
    "        self.out = nn.Linear(nh, em_sz, bias=False)\n",
    "        \n",
    "    def forward(self, inp1, inp2):\n",
    "        sl,bs = inp1.size()\n",
    "        h = self.initHidden(bs)\n",
    "        emb1 = self.emb_drop(self.emb(inp1))\n",
    "        emb2 = self.emb_drop(self.emb(inp2))\n",
    "        out_1, h1 = self.gru(emb1, h)\n",
    "        out_2, h2 = self.gru(emb2, h)\n",
    "        h1 = self.out(h1)\n",
    "        h2 = self.out(h2)\n",
    "        return F.cosine_similarity(h1[1],h2[1],dim=1)#[0].mean(dim=1)\n",
    "        #return h1[1]\n",
    "    \n",
    "    def initHidden(self, bs): return V(torch.zeros(self.nl, bs, self.nh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_fn = partial(optim.Adam, betas=(0.8, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 []\n"
     ]
    }
   ],
   "source": [
    "rnn = PairRNN(new_w, itos, em_sz, nh, bs=bs)\n",
    "learn = RNN_Learner(md, SingleModel(to_gpu(rnn)), opt_fn=opt_fn)\n",
    "learn.crit = nn.L1Loss()\n",
    "#learn.metrics = [accuracy]\n",
    "#nn.CosineEmbeddingLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.lr_find()\n",
    "#learn.fit(lr, 1, cycle_len=12, use_clr=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('quora2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PairRNN(\n",
       "  (emb): Embedding(41665, 400, padding_idx=1)\n",
       "  (emb_drop): Dropout(p=0.15)\n",
       "  (gru): GRU(400, 256, num_layers=2, dropout=0.25)\n",
       "  (out): Linear(in_features=256, out_features=400, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 752,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_inp = [\"i like apples\",\n",
    "         \"i want to buy some apples\",\n",
    "         \"where is your cell phone\"]\n",
    "\n",
    "x2_inp = [\"i like apples and oranges\",\n",
    "         \"i love all fruits especially apples and oranges\",\n",
    "         \"where is the new movie showing?\"]\n",
    "\n",
    "x3_inp = [\"let's talk about fruits for a second. Apples are nice. Oranges too. I kinda like them.\",\n",
    "         \"i compared the prices of apples and oranges at walmart and kroger stores\",\n",
    "         \"oh you wanna talk about apples. sure. i am not sure if i have said this before but i do like them and oranges.\"]\n",
    "\n",
    "x4_inp = [\"there is no comparison here. you are comparing apples to oranges\",\n",
    "         \"i compared the prices of apples and oranges at walmart and kroger stores\",\n",
    "         \"i don't see anything common between these two categories.\"]\n",
    "\n",
    "x5_inp = [\"i would love to own a nice boat and go sailing in the pacific ocean\",\n",
    "         \"i'm thinking of getting a fancy boat and set sail into the south pacific\",\n",
    "         \"i wish to own a small house and live there without any worries\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok1 = Tokenizer().proc_all(x1_inp,'en')\n",
    "tok2 = Tokenizer().proc_all(x2_inp,'en')\n",
    "tok3 = Tokenizer().proc_all(x3_inp,'en')\n",
    "tok4 = Tokenizer().proc_all(x4_inp,'en')\n",
    "tok5 = Tokenizer().proc_all(x5_inp,'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = [[stoi[o1] for o1 in o] for o in tok1]\n",
    "X2 = [[stoi[o1] for o1 in o] for o in tok2]\n",
    "X3 = [[stoi[o1] for o1 in o] for o in tok3]\n",
    "X4 = [[stoi[o1] for o1 in o] for o in tok4]\n",
    "X5 = [[stoi[o1] for o1 in o] for o in tok5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn = RNN_Learner(md, SingleModel(to_gpu(rnn)), opt_fn=opt_fn)\n",
    "def predict_similarities(m,sent0,sent1,sent2):\n",
    "    m.eval()\n",
    "    cc0 = learn.model((V(T([sent0]).permute(1,0))),(V(T([sent1]).permute(1,0))))\n",
    "    cc1 = learn.model((V(T([sent1]).permute(1,0))),(V(T([sent2]).permute(1,0))))\n",
    "    cc2 = learn.model((V(T([sent0]).permute(1,0))),(V(T([sent2]).permute(1,0))))\n",
    "    return cc0,cc1,cc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Round 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i like apples', 'i want to buy some apples', 'where is your cell phone']"
      ]
     },
     "execution_count": 873,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1_inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent0 = X1[0]; sent1 = X1[1]; sent2 = X1[2] #round 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Variable containing:\n",
      " 0.6741\n",
      "[torch.FloatTensor of size 1]\n",
      ", Variable containing:\n",
      " 0.4813\n",
      "[torch.FloatTensor of size 1]\n",
      ", Variable containing:\n",
      " 0.5396\n",
      "[torch.FloatTensor of size 1]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print (predict_similarities(learn.model,sent0,sent1,sent2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cos_sim results from previous model\n",
    "# 1: (0.9999998807907104, 0.06893263012170792, 0.06893263757228851)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Round 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i like apples and oranges',\n",
       " 'i love all fruits especially apples and oranges',\n",
       " 'where is the new movie showing?']"
      ]
     },
     "execution_count": 874,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2_inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent0 = X2[0]; sent1 = X2[1]; sent2 = X2[2] #round 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Variable containing:\n",
      " 0.9236\n",
      "[torch.FloatTensor of size 1]\n",
      ", Variable containing:\n",
      " 0.3989\n",
      "[torch.FloatTensor of size 1]\n",
      ", Variable containing:\n",
      " 0.3701\n",
      "[torch.FloatTensor of size 1]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print (predict_similarities(learn.model,sent0,sent1,sent2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cos_sim results from previous model\n",
    "# 2: (0.8213068842887878, 0.22487039864063263, 0.2921583652496338)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Round 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"let's talk about fruits for a second. Apples are nice. Oranges too. I kinda like them.\",\n",
       " 'i compared the prices of apples and oranges at walmart and kroger stores',\n",
       " 'oh you wanna talk about apples. sure. i am not sure if i have said this before but i do like them and oranges.']"
      ]
     },
     "execution_count": 875,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3_inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent0 = X3[0]; sent1 = X3[1]; sent2 = X3[2] #round 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Variable containing:\n",
      " 0.4416\n",
      "[torch.FloatTensor of size 1]\n",
      ", Variable containing:\n",
      " 0.7028\n",
      "[torch.FloatTensor of size 1]\n",
      ", Variable containing:\n",
      " 0.8711\n",
      "[torch.FloatTensor of size 1]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print (predict_similarities(learn.model,sent0,sent1,sent2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cos_sim results from previous model\n",
    "# 3: (0.043320432305336, 0.043320432305336, 1.0000001192092896)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Round 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['there is no comparison here. you are comparing apples to oranges',\n",
       " 'i compared the prices of apples and oranges at walmart and kroger stores',\n",
       " \"i don't see anything common between these two categories.\"]"
      ]
     },
     "execution_count": 876,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x4_inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent0 = X4[0]; sent1 = X4[1]; sent2 = X4[2] #round 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Variable containing:\n",
      " 0.4978\n",
      "[torch.FloatTensor of size 1]\n",
      ", Variable containing:\n",
      " 0.4850\n",
      "[torch.FloatTensor of size 1]\n",
      ", Variable containing:\n",
      " 0.6487\n",
      "[torch.FloatTensor of size 1]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print (predict_similarities(learn.model,sent0,sent1,sent2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cos_sim results from previous model\n",
    "# 4: (0.0017274579731747508, 0.043320432305336, 0.02612287364900112)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Round 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i would love to own a nice boat and go sailing in the pacific ocean',\n",
       " \"i'm thinking of getting a fancy boat and set sail into the south pacific\",\n",
       " 'i wish to own a small house and live there without any worries']"
      ]
     },
     "execution_count": 877,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x5_inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent0 = X5[0]; sent1 = X5[1]; sent2 = X5[2] #round 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Variable containing:\n",
      " 0.8350\n",
      "[torch.FloatTensor of size 1]\n",
      ", Variable containing:\n",
      " 0.5553\n",
      "[torch.FloatTensor of size 1]\n",
      ", Variable containing:\n",
      " 0.6052\n",
      "[torch.FloatTensor of size 1]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print (predict_similarities(learn.model,sent0,sent1,sent2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cos_sim results from previous model\n",
    "# 5: (0.5177718997001648, 0.14863775670528412, 0.046706970781087875)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.load('quora2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since sim(A,B) = sim (B,A) we can double the dataset.\n",
    "TODO: Train model with twice the data after commutating."
   ]
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/0dd0df21cf404cf2bb51d0148c8b7d8b"
  },
  "gist": {
   "data": {
    "description": "fastai.text imdb example",
    "public": true
   },
   "id": "0dd0df21cf404cf2bb51d0148c8b7d8b"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "86px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
